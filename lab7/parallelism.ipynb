{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb0f1de",
   "metadata": {},
   "source": [
    "## Running on multiple GPUs using Hugging Face Transformers\n",
    "\n",
    "Naive pipeline parallelism is supported out of the box. For this, simply load the model with device=\"auto\" which will automatically place the different layers on the available GPUs.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Create a pod with two 24GB GPUs.\n",
    "\n",
    "2. Try to run the model with device=\"auto\" and see how much VRAM is used. You can also try to run the model with device_map=\"auto\" which will automatically place the different layers on the available GPUs. This is a more advanced version of pipeline parallelism that allows for more flexibility in how the model is distributed across GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04b442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/ssdshare/share/Meta-Llama-3-8B-Instruct/\"\n",
    "# TODO(Your Task): Load the model to multiple GPUs and check the GPU memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a493ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd5e3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea7b1254e3046ff9fd1f31db7c6a569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation='flash_attention_2',\n",
    "    device_map='cuda:0'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f7f0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Paris. France is a country located in Western Europe, and its capital is Paris. The country is known for its rich history, art, fashion, and cuisine, and is home to many famous landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. The capital city of Paris is a major tourist destination and is known for its romantic atmosphere, charming streets, and vibrant cultural scene. The city is also a major hub for international business and diplomacy, and is home to many international organizations such as the United Nations Educational, Scientific and Cultural Organization (UNESCO). The capital of France is Paris. France is a country located in Western Europe, and its capital is Paris. The country is known for its rich history, art, fashion, and cuisine, and is home to many famous landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. The capital city of Paris is a major tourist destination and is known for its romantic atmosphere, charming streets, and vibrant cultural scene. The city is also a major hub for international business and diplomacy, and is home to many international organizations such as the United Nations Educational, Scientific and Cultural Organization (UNESCO). The capital of France is Paris. France is a country located in Western Europe, and its capital is Paris. The country is known for its rich history, art, fashion, and cuisine, and is home to many famous landmarks such as the Eiffel Tower, the Lou'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Question: What is the capital of France?\\n\\nAnswer:\"\n",
    "\n",
    "result = pipe(prompt, max_new_tokens=300, pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"][len(prompt):]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f851a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_giga_bytes(bytes):\n",
    "    gigabytes = bytes / (1024**3)\n",
    "    return gigabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd410fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.009931087493896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes_to_giga_bytes(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aa8fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbda08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "tokenizer = None\n",
    "pipe = None\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a466a279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce5c83e0bda478fb28e9c520a72bdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation='flash_attention_2',\n",
    "    device_map='auto'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8bbd229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Paris.  #France #Paris #CapitalCity #EuropeanCountry #Travel #Geography #Country #Capital #City #European #FranceCapital #ParisCapital #TravelGuide #TravelTips #TravelInformation #TravelGuide #TravelTips #TravelInformation #Travel #FranceTravel #ParisTravel #CapitalCity #EuropeanCountry #Geography #Country #Capital #City #European #FranceCapital #ParisCapital #TravelGuide #TravelTips #TravelInformation #Travel #FranceTravel #ParisTravel #CapitalCity #EuropeanCountry #Geography #Country #Capital #City #European #FranceCapital #ParisCapital #TravelGuide #TravelTips #TravelInformation #Travel #FranceTravel #ParisTravel #CapitalCity #EuropeanCountry #Geography #Country #Capital #City #European #FranceCapital #ParisCapital #TravelGuide #TravelTips #TravelInformation #Travel #FranceTravel #ParisTravel #CapitalCity #EuropeanCountry #Geography #Country #Capital #City #European #FranceCapital #ParisCapital #TravelGuide #TravelTips #TravelInformation #Travel #FranceTravel #ParisTravel #CapitalCity #EuropeanCountry #Geography #Country #Capital #City #European #FranceCapital #ParisCapital #TravelGuide #TravelTips #TravelInformation #Travel #FranceTravel #ParisTravel #CapitalCity #EuropeanCountry #Geography #Country #Capital #City #European #FranceCapital #ParisCapital #TravelGuide #TravelTips #TravelInformation #Travel #FranceTravel #ParisTravel #Capital'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipe(prompt, max_new_tokens=300, pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"][len(prompt):]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26e59a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.69680643081665\n",
      "8.321207523345947\n"
     ]
    }
   ],
   "source": [
    "print(bytes_to_giga_bytes(torch.cuda.max_memory_allocated(0)))\n",
    "print(bytes_to_giga_bytes(torch.cuda.max_memory_allocated(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d168c7",
   "metadata": {},
   "source": [
    "The GPU memory usage of loading the model to only one GPU is 15.01GB.\n",
    "\n",
    "The GPU memory usage of loading the model with device=\"auto\" is **This argument is invalid**. The GPU memory usage of loading the model with device_map=\"auto\" is 6.70GB, 8.32GB.\n",
    "\n",
    "The number of GPUs you used is 1 for `device_map='cuda:0'`, 2 for `device_map='auto'`.\n",
    "\n",
    "Does the numbers above make sense?\n",
    "\n",
    "Yes. The total GPU memory usage of loading the model with `device_map='auto'` is 6.70GB + 8.32GB = 15.02GB, which is almost the same as loading the model to only one GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
